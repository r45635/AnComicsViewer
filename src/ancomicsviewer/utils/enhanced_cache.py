#!/usr/bin/env python3
"""
Cache syst√®me avanc√© pour AnComicsViewer
Optimise les performances avec mise en cache persistante et intelligente
"""

import os
import json
import hashlib
import pickle
import threading
from typing import Dict, List, Optional, Tuple
from pathlib import Path
from PySide6.QtCore import QRectF, QSizeF, QObject, QThread, Signal
import time

class PanelCacheManager:
    """
    Gestionnaire de cache intelligent pour les d√©tections de panels.
    
    Features:
    - Cache m√©moire rapide (session active)
    - Cache disque persistant (entre sessions)
    - Invalidation intelligente (fichier modifi√©, param√®tres chang√©s)
    - Preload en arri√®re-plan des pages suivantes
    - Compression pour √©conomiser l'espace disque
    """
    
    def __init__(self, cache_dir: Optional[str] = None):
        self.cache_dir = Path(cache_dir or (Path.home() / ".ancomicsviewer" / "cache"))
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # Cache m√©moire (session courante)
        self._memory_cache: Dict[str, Dict[int, List[QRectF]]] = {}
        
        # M√©tadonn√©es des fichiers
        self._file_metadata: Dict[str, dict] = {}
        
        # Cache des hashs de param√®tres d√©tecteur
        self._detector_hashes: Dict[str, str] = {}
        
        # Statistiques
        self.stats = {
            "memory_hits": 0,
            "disk_hits": 0, 
            "misses": 0,
            "saves": 0
        }
        
        # Lock pour thread safety
        self._lock = threading.RLock()
        
        print(f"üìÅ Cache initialis√©: {self.cache_dir}")
    
    def _get_file_hash(self, pdf_path: str) -> str:
        """Calcule un hash unique pour le fichier PDF."""
        try:
            stat = os.stat(pdf_path)
            content = f"{pdf_path}:{stat.st_size}:{stat.st_mtime}"
            return hashlib.md5(content.encode()).hexdigest()[:16]
        except:
            return hashlib.md5(pdf_path.encode()).hexdigest()[:16]
    
    def _get_detector_hash(self, detector) -> str:
        """G√©n√®re un hash bas√© sur les param√®tres du d√©tecteur."""
        try:
            # VERSION DE CACHE - v5 avec panels-by-name
            CACHE_VERSION = "v5-panels-by-name"
            
            # R√©cup√®re les param√®tres principaux du d√©tecteur
            params = {
                "cache_version": CACHE_VERSION,  # ‚Üê Force la r√©g√©n√©ration du cache
                "device": getattr(detector, 'device', 'cpu'),
                "model_name": getattr(detector, 'model_name', 'unknown')
            }
            
            # Ajoute la config BD si disponible
            if hasattr(detector, 'config'):
                config = detector.config
                params.update({
                    "conf_base": getattr(config, 'CONF_BASE', 0.15),
                    "conf_min": getattr(config, 'CONF_MIN', 0.05),
                    "iou_nms": getattr(config, 'IOU_NMS', 0.5),
                    "target_min": getattr(config, 'TARGET_MIN', 2),
                    "target_max": getattr(config, 'TARGET_MAX', 20),
                })
            
            # Ajoute la signature des noms de classes du mod√®le si disponible
            if hasattr(detector, 'get_model_names_signature'):
                try:
                    params["model_names_sig"] = detector.get_model_names_signature()
                except:
                    pass
                
            # Ajoute tous les autres param√®tres publics (fallback)
            for key, value in detector.__dict__.items():
                if not key.startswith('_') and not callable(value):
                    try:
                        params[key] = str(value)
                    except:
                        continue
            
            param_str = json.dumps(params, sort_keys=True)
            return hashlib.md5(param_str.encode()).hexdigest()[:12]
        except:
            pass
        return "default_v4"
    
    def _get_cache_key(self, pdf_path: str, detector) -> Tuple[str, str]:
        """G√©n√®re les cl√©s de cache pour un fichier et d√©tecteur."""
        file_hash = self._get_file_hash(pdf_path)
        detector_hash = self._get_detector_hash(detector)
        return file_hash, detector_hash
    
    def _get_cache_file(self, pdf_path: str, detector) -> Path:
        """Retourne le chemin du fichier de cache."""
        file_hash, detector_hash = self._get_cache_key(pdf_path, detector)
        cache_filename = f"{file_hash}_{detector_hash}.cache"
        return self.cache_dir / cache_filename
    
    def get_panels(self, pdf_path: str, page: int, detector) -> Optional[List[QRectF]]:
        """
        R√©cup√®re les panels depuis le cache (m√©moire puis disque).
        
        Returns:
            List[QRectF] si trouv√© dans le cache, None sinon
        """
        with self._lock:
            cache_key = self._get_cache_key(pdf_path, detector)[0]
            
            # 1. V√©rifier le cache m√©moire
            if cache_key in self._memory_cache:
                if page in self._memory_cache[cache_key]:
                    self.stats["memory_hits"] += 1
                    return self._memory_cache[cache_key][page]
            
            # 2. V√©rifier le cache disque
            cache_file = self._get_cache_file(pdf_path, detector)
            if cache_file.exists():
                try:
                    with open(cache_file, 'rb') as f:
                        cache_data = pickle.load(f)
                    
                    if page in cache_data.get('pages', {}):
                        panels_data = cache_data['pages'][page]
                        
                        # Reconstruire les QRectF
                        panels = []
                        for rect_data in panels_data:
                            rect = QRectF(rect_data['x'], rect_data['y'], 
                                        rect_data['w'], rect_data['h'])
                            panels.append(rect)
                        
                        # Mettre en cache m√©moire pour la prochaine fois
                        if cache_key not in self._memory_cache:
                            self._memory_cache[cache_key] = {}
                        self._memory_cache[cache_key][page] = panels
                        
                        self.stats["disk_hits"] += 1
                        return panels
                        
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erreur lecture cache {cache_file}: {e}")
            
            self.stats["misses"] += 1
            return None
    
    def save_panels(self, pdf_path: str, page: int, panels: List[QRectF], detector):
        """
        Sauvegarde les panels dans le cache (m√©moire + disque).
        ‚ö†Ô∏è NE SAUVEGARDE PAS les r√©sultats vides pour laisser une 2e chance.
        """
        with self._lock:
            # Ne pas sauvegarder les r√©sultats vides dans le cache
            if not panels or len(panels) == 0:
                print(f"[Cache] Skipping empty result for page {page} (no cache write)")
                return
            
            cache_key = self._get_cache_key(pdf_path, detector)[0]
            
            # 1. Cache m√©moire
            if cache_key not in self._memory_cache:
                self._memory_cache[cache_key] = {}
            self._memory_cache[cache_key][page] = panels
            
            # 2. Cache disque
            cache_file = self._get_cache_file(pdf_path, detector)
            
            try:
                # Charger les donn√©es existantes ou cr√©er nouvelles
                cache_data = {'pages': {}, 'metadata': {}}
                if cache_file.exists():
                    with open(cache_file, 'rb') as f:
                        cache_data = pickle.load(f)
                
                # Convertir QRectF en donn√©es s√©rialisables
                panels_data = []
                for rect in panels:
                    panels_data.append({
                        'x': rect.x(),
                        'y': rect.y(), 
                        'w': rect.width(),
                        'h': rect.height()
                    })
                
                cache_data['pages'][page] = panels_data
                cache_data['metadata'] = {
                    'timestamp': time.time(),
                    'detector_type': type(detector).__name__,
                    'panel_count': len(panels)
                }
                
                # Sauvegarder
                with open(cache_file, 'wb') as f:
                    pickle.dump(cache_data, f, protocol=pickle.HIGHEST_PROTOCOL)
                
                self.stats["saves"] += 1
                
            except Exception as e:
                print(f"‚ö†Ô∏è  Erreur sauvegarde cache {cache_file}: {e}")
    
    def clear_file_cache(self, pdf_path: str):
        """Efface le cache pour un fichier PDF sp√©cifique."""
        with self._lock:
            file_hash = self._get_file_hash(pdf_path)
            
            # Cache m√©moire
            if file_hash in self._memory_cache:
                del self._memory_cache[file_hash]
            
            # Cache disque - supprimer tous les fichiers avec ce hash
            pattern = f"{file_hash}_*.cache"
            for cache_file in self.cache_dir.glob(pattern):
                try:
                    cache_file.unlink()
                    print(f"üóëÔ∏è  Cache supprim√©: {cache_file.name}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erreur suppression {cache_file}: {e}")
    
    def clear_all_cache(self):
        """Efface tout le cache."""
        with self._lock:
            # Cache m√©moire
            self._memory_cache.clear()
            
            # Cache disque
            for cache_file in self.cache_dir.glob("*.cache"):
                try:
                    cache_file.unlink()
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erreur suppression {cache_file}: {e}")
            
            print("üßπ Cache compl√®tement vid√©")
    
    def get_cache_info(self) -> dict:
        """Retourne les informations sur le cache."""
        with self._lock:
            memory_files = len(self._memory_cache)
            memory_pages = sum(len(pages) for pages in self._memory_cache.values())
            
            disk_files = len(list(self.cache_dir.glob("*.cache")))
            disk_size = sum(f.stat().st_size for f in self.cache_dir.glob("*.cache"))
            
            return {
                "memory": {
                    "files": memory_files,
                    "pages": memory_pages
                },
                "disk": {
                    "files": disk_files,
                    "size_mb": disk_size / (1024 * 1024),
                    "path": str(self.cache_dir)
                },
                "stats": self.stats.copy()
            }
    
    def cleanup_old_cache(self, max_age_days: int = 30):
        """Nettoie les fichiers de cache anciens."""
        cutoff_time = time.time() - (max_age_days * 24 * 3600)
        cleaned = 0
        
        for cache_file in self.cache_dir.glob("*.cache"):
            try:
                if cache_file.stat().st_mtime < cutoff_time:
                    cache_file.unlink()
                    cleaned += 1
            except Exception as e:
                print(f"‚ö†Ô∏è  Erreur nettoyage {cache_file}: {e}")
        
        if cleaned > 0:
            print(f"üßπ {cleaned} fichiers de cache anciens supprim√©s")


class PreloadWorker(QThread):
    """
    Worker thread pour preload des pages suivantes en arri√®re-plan.
    """
    
    preload_completed = Signal(int, list)  # page, panels
    
    def __init__(self, pdf_path: str, pages_to_load: List[int], detector, document):
        super().__init__()
        self.pdf_path = pdf_path
        self.pages_to_load = pages_to_load
        self.detector = detector
        self.document = document
        self._stop_requested = False
    
    def stop(self):
        self._stop_requested = True
    
    def run(self):
        """Pr√©charge les pages en arri√®re-plan."""
        for page in self.pages_to_load:
            if self._stop_requested:
                break
            
            try:
                # Simuler la d√©tection (remplacer par la vraie logique)
                pt = self.document.pagePointSize(page)
                dpi = 200  # DPI par d√©faut
                scale = dpi / 72.0
                qsize = QSizeF(pt.width() * scale, pt.height() * scale).toSize()
                qimg = self.document.render(page, qsize)
                
                panels = self.detector.detect_panels(qimg, pt)
                
                self.preload_completed.emit(page, panels)
                
                # Petite pause pour ne pas surcharger
                self.msleep(100)
                
            except Exception as e:
                print(f"‚ö†Ô∏è  Erreur preload page {page}: {e}")


def create_enhanced_cache_test():
    """Cr√©e un test pour le syst√®me de cache avanc√©."""
    print("üß™ Test du Cache Manager Enhanced")
    print("=" * 40)
    
    # Cr√©er le cache manager
    cache_manager = PanelCacheManager()
    
    # Simuler un d√©tecteur simple
    class MockDetector:
        def __init__(self):
            self.adaptive_block = 51
            self.min_rect_px = 80
            self.confidence = 0.25
    
    detector = MockDetector()
    pdf_path = "/test/comics.pdf"
    
    # Test 1: Cache miss
    print("1. Test cache miss...")
    panels = cache_manager.get_panels(pdf_path, 0, detector)
    assert panels is None
    print("   ‚úÖ Cache miss d√©tect√©")
    
    # Test 2: Sauvegarde
    print("2. Test sauvegarde...")
    test_panels = [
        QRectF(10, 10, 100, 150),
        QRectF(120, 10, 100, 150),
        QRectF(10, 170, 210, 100)
    ]
    cache_manager.save_panels(pdf_path, 0, test_panels, detector)
    print("   ‚úÖ Panels sauvegard√©s")
    
    # Test 3: Cache hit m√©moire
    print("3. Test cache hit m√©moire...")
    cached_panels = cache_manager.get_panels(pdf_path, 0, detector)
    assert cached_panels is not None
    assert len(cached_panels) == 3
    print(f"   ‚úÖ {len(cached_panels)} panels r√©cup√©r√©s de la m√©moire")
    
    # Test 4: Cache hit disque (simuler red√©marrage)
    print("4. Test cache hit disque...")
    cache_manager._memory_cache.clear()  # Vider la m√©moire
    cached_panels = cache_manager.get_panels(pdf_path, 0, detector)
    assert cached_panels is not None
    assert len(cached_panels) == 3
    print(f"   ‚úÖ {len(cached_panels)} panels r√©cup√©r√©s du disque")
    
    # Test 5: Informations cache
    print("5. Test informations cache...")
    info = cache_manager.get_cache_info()
    print(f"   üìä M√©moire: {info['memory']['files']} fichiers, {info['memory']['pages']} pages")
    print(f"   üíæ Disque: {info['disk']['files']} fichiers, {info['disk']['size_mb']:.1f} MB")
    print(f"   üìà Stats: {info['stats']}")
    
    # Test 6: Nettoyage
    print("6. Test nettoyage...")
    cache_manager.clear_file_cache(pdf_path)
    panels = cache_manager.get_panels(pdf_path, 0, detector)
    assert panels is None
    print("   ‚úÖ Cache nettoy√©")
    
    print()
    print("üéâ Tous les tests du cache pass√©s!")
    
    return cache_manager

if __name__ == "__main__":
    create_enhanced_cache_test()
