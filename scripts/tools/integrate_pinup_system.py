#!/usr/bin/env python3
"""
IntÃ©gration de "La Pin-up du B24" dans le dataset multi-BD
Version utilisant pdftoppm (systÃ¨me)
"""

import os
import subprocess
from pathlib import Path
import shutil

def check_dependencies():
    """VÃ©rifie que pdftoppm est disponible."""
    try:
        result = subprocess.run(['pdftoppm', '-h'], capture_output=True, text=True)
        return True
    except FileNotFoundError:
        print("âŒ pdftoppm non trouvÃ©. Installation requise:")
        print("   macOS: brew install poppler")
        print("   Ou utiliser une autre mÃ©thode d'extraction PDF")
        return False

def extract_pinup_pages_system():
    """Extrait les pages avec pdftoppm (systÃ¨me)."""
    
    print("ðŸ“– INTÃ‰GRATION DE LA PIN-UP DU B24")
    print("=" * 40)
    
    # Fichiers source et destination
    pdf_path = "La Pin-up du B24 - T01.pdf"
    output_dir = Path("dataset/images/train")
    temp_dir = Path("temp_pinup_extraction")
    
    if not Path(pdf_path).exists():
        print(f"âŒ PDF non trouvÃ©: {pdf_path}")
        return 0
    
    print(f"ðŸ“ Source: {pdf_path}")
    print(f"ðŸ“ Destination: {output_dir}")
    
    # CrÃ©er les dossiers
    output_dir.mkdir(parents=True, exist_ok=True)
    temp_dir.mkdir(exist_ok=True)
    
    try:
        # Extraire avec pdftoppm
        print("ðŸ”„ Extraction des pages en cours...")
        
        cmd = [
            'pdftoppm',
            '-png',           # Format PNG
            '-r', '200',      # 200 DPI pour bonne qualitÃ©
            '-f', '1',        # PremiÃ¨re page
            '-l', '50',       # DerniÃ¨re page (max 50)
            pdf_path,
            str(temp_dir / 'pinup_page')
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"âŒ Erreur pdftoppm: {result.stderr}")
            return 0
        
        # Renommer et dÃ©placer les fichiers
        extracted_files = list(temp_dir.glob("pinup_page-*.png"))
        extracted_count = 0
        
        for i, temp_file in enumerate(sorted(extracted_files), 1):
            # Nouveau nom avec format standard
            new_name = f"pinup_p{i:04d}.png"
            final_path = output_dir / new_name
            
            # DÃ©placer le fichier
            shutil.move(str(temp_file), str(final_path))
            extracted_count += 1
            
            if extracted_count % 10 == 0:
                print(f"   âœ… {extracted_count} pages traitÃ©es...")
        
        # Nettoyer le dossier temporaire
        shutil.rmtree(temp_dir)
        
        print(f"âœ… Extraction terminÃ©e: {extracted_count} pages de La Pin-up du B24")
        return extracted_count
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        if temp_dir.exists():
            shutil.rmtree(temp_dir)
        return 0

def extract_pinup_pages_manual():
    """Instructions pour extraction manuelle."""
    
    print("ðŸ“– EXTRACTION MANUELLE - LA PIN-UP DU B24")
    print("=" * 45)
    print()
    print("ðŸ”§ MÃ‰THODE ALTERNATIVE (si pdftoppm indisponible):")
    print()
    print("1. ðŸ“± Ouvre le PDF dans AperÃ§u (Preview)")
    print("2. ðŸ–¼ï¸  SÃ©lectionne les 30-50 premiÃ¨res pages")
    print("3. ðŸ“ Exporte en PNG (Fichier > Exporter)")
    print("4. ðŸ“ Nomme les fichiers: pinup_p0001.png, pinup_p0002.png...")
    print("5. ðŸ“‚ Place-les dans: dataset/images/train/")
    print()
    print("ðŸ“‹ CONVENTION DE NOMMAGE:")
    print("   pinup_p0001.png")
    print("   pinup_p0002.png") 
    print("   pinup_p0003.png")
    print("   ...")
    print()
    print("ðŸ’¡ Une fois fait, relance ce script pour voir les stats")

def analyze_updated_dataset():
    """Analyse le dataset aprÃ¨s ajout potentiel de La Pin-up du B24."""
    
    print("\nðŸ“Š STATISTIQUES DU DATASET ACTUEL")
    print("=" * 40)
    
    train_dir = Path("dataset/images/train")
    if not train_dir.exists():
        print("âŒ Dossier dataset non trouvÃ©")
        return
    
    # Compter par sÃ©rie
    all_images = list(train_dir.glob("*.png"))
    
    series_counts = {
        "Golden City": len([f for f in all_images if f.name.startswith("p") and not any(x in f.name for x in ["tintin", "pinup"])]),
        "Tintin": len([f for f in all_images if f.name.startswith("tintin_")]),
        "Pin-up du B24": len([f for f in all_images if f.name.startswith("pinup_")])
    }
    
    # Compter les annotations
    labels_dir = Path("dataset/labels/train")
    series_annotations = {
        "Golden City": 0,
        "Tintin": 0, 
        "Pin-up du B24": 0
    }
    
    if labels_dir.exists():
        for json_file in labels_dir.glob("*.json"):
            name = json_file.stem
            if name.startswith("p") and not any(x in name for x in ["tintin", "pinup"]):
                series_annotations["Golden City"] += 1
            elif name.startswith("tintin_"):
                series_annotations["Tintin"] += 1
            elif name.startswith("pinup_"):
                series_annotations["Pin-up du B24"] += 1
    
    # Afficher les statistiques
    total_images = sum(series_counts.values())
    total_annotations = sum(series_annotations.values())
    
    print("SÃ©rie                | Images | AnnotÃ©es | Couverture")
    print("-" * 50)
    
    for series in series_counts:
        img_count = series_counts[series]
        ann_count = series_annotations[series]
        coverage = (ann_count / img_count) * 100 if img_count > 0 else 0
        
        print(f"{series:<20} | {img_count:6} | {ann_count:8} | {coverage:7.1f}%")
    
    print("-" * 50)
    print(f"{'TOTAL':<20} | {total_images:6} | {total_annotations:8} | {(total_annotations/total_images)*100:7.1f}%")
    
    # Recommandations d'annotation
    print("\nðŸ’¡ PRIORITÃ‰S D'ANNOTATION:")
    
    for series in series_counts:
        img_count = series_counts[series]
        ann_count = series_annotations[series]
        
        if img_count == 0:
            continue
            
        coverage = (ann_count / img_count) * 100
        target = min(20, max(10, img_count // 3))  # Cible: 10-20 annotations par sÃ©rie
        needed = max(0, target - ann_count)
        
        if needed > 0:
            priority = "ðŸ”´ HAUTE" if coverage < 15 else "ðŸŸ¡ MOYENNE" if coverage < 30 else "ðŸŸ¢ BASSE"
            print(f"   {priority}: {series} - annoter {needed} images de plus")
        else:
            print(f"   âœ… {series}: couverture suffisante ({coverage:.1f}%)")

def main():
    """Fonction principale."""
    
    print("ðŸš€ AJOUT DE LA PIN-UP DU B24 AU DATASET")
    print("=" * 50)
    print()
    
    # VÃ©rifier d'abord s'il y a dÃ©jÃ  des fichiers Pin-up
    train_dir = Path("dataset/images/train")
    existing_pinup = len(list(train_dir.glob("pinup_*.png"))) if train_dir.exists() else 0
    
    if existing_pinup > 0:
        print(f"ðŸ“ {existing_pinup} fichiers Pin-up dÃ©jÃ  prÃ©sents")
        analyze_updated_dataset()
        return
    
    # Essayer l'extraction automatique
    if check_dependencies():
        extracted = extract_pinup_pages_system()
        if extracted > 0:
            analyze_updated_dataset()
            print(f"\nâœ… INTÃ‰GRATION TERMINÃ‰E!")
            print(f"ðŸ“ˆ {extracted} nouvelles pages ajoutÃ©es")
            print(f"ðŸŽ¯ Prochaine Ã©tape: annoter les images Pin-up du B24")
            print(f"ðŸ’¡ Utilise: python start_annotation.py")
        else:
            print("\nðŸ”„ Extraction automatique Ã©chouÃ©e, passage en manuel...")
            extract_pinup_pages_manual()
    else:
        # MÃ©thode manuelle si pdftoppm indisponible
        extract_pinup_pages_manual()
        analyze_updated_dataset()

if __name__ == "__main__":
    main()
